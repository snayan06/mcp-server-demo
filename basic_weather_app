import requests
from openai import OpenAI

# ------------------------------------------------------------------------------
# ğŸ§  STEP 0: OpenAI Client Initialization
# ------------------------------------------------------------------------------
client = OpenAI(
)

# ------------------------------------------------------------------------------
# ğŸŒ STEP 1: Geocode the City Name to Latitude/Longitude
# ------------------------------------------------------------------------------
city = "Pune, India"
geo_resp = requests.get(
    "https://geocoding-api.open-meteo.com/v1/search", 
    params={"name": city, "count": 1}
)
geo_resp.raise_for_status()

geo_data = geo_resp.json().get("results", [{}])[0]
LATITUDE = geo_data.get("latitude")
LONGITUDE = geo_data.get("longitude")

# ------------------------------------------------------------------------------
# ğŸŒ¦ STEP 2: Fetch Current Weather Using Open-Meteo API (No API key needed)
# ------------------------------------------------------------------------------
weather_resp = requests.get(
    "https://api.open-meteo.com/v1/forecast",
    params={"latitude": LATITUDE, "longitude": LONGITUDE, "current_weather": True},
    timeout=10,
)
weather_resp.raise_for_status()

weather = weather_resp.json().get("current_weather", {})

# ------------------------------------------------------------------------------
# ğŸ“ STEP 3: Inject Weather Data as Freeform Text into a Prompt
# ------------------------------------------------------------------------------
plain_prompt = f"""
You are a weather assistant.
Here's the current weather in {city}:
  â€¢ Temperature: {weather.get('temperature')}Â°C
  â€¢ Wind Speed: {weather.get('windspeed')} km/h
  â€¢ Wind Direction: {weather.get('winddirection')}Â°
Write a friendly weather summary.
"""

# ------------------------------------------------------------------------------
# ğŸ¤– STEP 4: Call OpenAI GPT-4o with the Raw Prompt
# ------------------------------------------------------------------------------
response = client.chat.completions.create(
    model="gpt-4o",
    messages=[{"role": "user", "content": plain_prompt}]
)

# ------------------------------------------------------------------------------
# ğŸ“¤ STEP 5: Display the Resulting Summary from the Model
# ------------------------------------------------------------------------------
print(f"ğŸ•° Old-style summary for {city}:")
print(response.choices[0].message.content)

# ------------------------------------------------------------------------------
# â—ï¸ WHY THIS APPROACH DOESNâ€™T SCALE (to be shown in the talk)
# ------------------------------------------------------------------------------
"""
ğŸš¨ Limitations of this legacy approach (pre-Function Calling, pre-Tool Use, pre-MCP):

1. âŒ Prompt Stuffing

2. âŒ No Schema or Structure

3. âŒ No Separation of Concerns

4. âŒ Zero Observability or Reusability

5. âŒ Assumes Happy Path

ğŸ”¥ TL;DR:
This worked *okay* for demos. But in real-world applications, especially agentic systems,
you need schema, structure, error handling, traceability, and reusability 

"""